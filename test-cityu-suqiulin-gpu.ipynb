{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matters need attention:\n",
    "## 1. Please make sure the attachment file cityu.pth (model I pretrain) is on the same directory as this .ipynb\n",
    "## 2. Only you need to modify is the last cell, after that just click \"Run All\" to get the result\n",
    "## 3. Please email me the result, or any problem using zoom to make a quick check together if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/732_2ppd3f923nnybyb6pz1c0000gp/T/ipykernel_98916/529153938.py:16: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n"
     ]
    }
   ],
   "source": [
    "# import depedencies\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import cv2\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from io import BytesIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet.py\n",
    "__all__ = [\"ResNet\", \"resnet18\", \"resnet34\",\n",
    "           \"resnet50\", \"resnet101\", \"resnet152\"]\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    \"resnet18\": \"https://download.pytorch.org/models/resnet18-5c106cde.pth\",\n",
    "    \"resnet34\": \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\",\n",
    "    \"resnet50\": \"https://download.pytorch.org/models/resnet50-19c8e357.pth\",\n",
    "    \"resnet101\": \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\",\n",
    "    \"resnet152\": \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\",\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super().__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7,\n",
    "                               stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = [block(self.inplanes, planes, stride, downsample)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        layers.extend(block(self.inplanes, planes) for _ in range(1, blocks))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, *args):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls[\"resnet18\"]))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls[\"resnet34\"]))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls[\"resnet50\"]))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls[\"resnet101\"]))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls[\"resnet152\"]))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "#srm_conv.py\n",
    "class SRMConv2d_simple(nn.Module):\n",
    "\n",
    "    def __init__(self, inc=3, learnable=False):\n",
    "        super(SRMConv2d_simple, self).__init__()\n",
    "        self.truc = nn.Hardtanh(-3, 3)\n",
    "        kernel = self._build_kernel(inc)  # (3,3,5,5)\n",
    "        self.kernel = nn.Parameter(data=kernel, requires_grad=learnable)\n",
    "        # self.hor_kernel = self._build_kernel().transpose(0,1,3,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: imgs (Batch, H, W, 3)\n",
    "        '''\n",
    "        out = F.conv2d(x, self.kernel, stride=1, padding=2)\n",
    "        out = self.truc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _build_kernel(self, inc):\n",
    "        # filter1: KB\n",
    "        filter1 = [[0, 0, 0, 0, 0],\n",
    "                   [0, -1, 2, -1, 0],\n",
    "                   [0, 2, -4, 2, 0],\n",
    "                   [0, -1, 2, -1, 0],\n",
    "                   [0, 0, 0, 0, 0]]\n",
    "        # filter2：KV\n",
    "        filter2 = [[-1, 2, -2, 2, -1],\n",
    "                   [2, -6, 8, -6, 2],\n",
    "                   [-2, 8, -12, 8, -2],\n",
    "                   [2, -6, 8, -6, 2],\n",
    "                   [-1, 2, -2, 2, -1]]\n",
    "        # filter3：hor 2rd\n",
    "        filter3 = [[0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0],\n",
    "                   [0, 1, -2, 1, 0],\n",
    "                   [0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0]]\n",
    "\n",
    "        filter1 = np.asarray(filter1, dtype=float) / 4.\n",
    "        filter2 = np.asarray(filter2, dtype=float) / 12.\n",
    "        filter3 = np.asarray(filter3, dtype=float) / 2.\n",
    "        # statck the filters\n",
    "        filters = [[filter1],  # , filter1, filter1],\n",
    "                   [filter2],  # , filter2, filter2],\n",
    "                   [filter3]]  # , filter3, filter3]]  # (3,3,5,5)\n",
    "        filters = np.array(filters)\n",
    "        filters = np.repeat(filters, inc, axis=1)\n",
    "        filters = torch.FloatTensor(filters)    # (3,3,5,5)\n",
    "        return filters\n",
    "\n",
    "\n",
    "class SRMConv2d_Separate(nn.Module):\n",
    "\n",
    "    def __init__(self, inc, outc, learnable=False):\n",
    "        super(SRMConv2d_Separate, self).__init__()\n",
    "        self.inc = inc\n",
    "        self.truc = nn.Hardtanh(-3, 3)\n",
    "        kernel = self._build_kernel(inc)  # (3,3,5,5)\n",
    "        self.kernel = nn.Parameter(data=kernel, requires_grad=learnable)\n",
    "        # self.hor_kernel = self._build_kernel().transpose(0,1,3,2)\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.Conv2d(3*inc, outc, 1, 1, 0, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(outc),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        for ly in self.out_conv.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: imgs (Batch, H, W, 3)\n",
    "        '''\n",
    "        out = F.conv2d(x, self.kernel, stride=1, padding=2, groups=self.inc)\n",
    "        out = self.truc(out)\n",
    "        out = self.out_conv(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _build_kernel(self, inc):\n",
    "        # filter1: KB\n",
    "        filter1 = [[0, 0, 0, 0, 0],\n",
    "                   [0, -1, 2, -1, 0],\n",
    "                   [0, 2, -4, 2, 0],\n",
    "                   [0, -1, 2, -1, 0],\n",
    "                   [0, 0, 0, 0, 0]]\n",
    "        # filter2：KV\n",
    "        filter2 = [[-1, 2, -2, 2, -1],\n",
    "                   [2, -6, 8, -6, 2],\n",
    "                   [-2, 8, -12, 8, -2],\n",
    "                   [2, -6, 8, -6, 2],\n",
    "                   [-1, 2, -2, 2, -1]]\n",
    "        # # filter3：hor 2rd\n",
    "        filter3 = [[0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0],\n",
    "                   [0, 1, -2, 1, 0],\n",
    "                   [0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0]]\n",
    "\n",
    "        filter1 = np.asarray(filter1, dtype=float) / 4.\n",
    "        filter2 = np.asarray(filter2, dtype=float) / 12.\n",
    "        filter3 = np.asarray(filter3, dtype=float) / 2.\n",
    "        # statck the filters\n",
    "        filters = [[filter1],  # , filter1, filter1],\n",
    "                   [filter2],  # , filter2, filter2],\n",
    "                   [filter3]]  # , filter3, filter3]]  # (3,3,5,5)\n",
    "        filters = np.array(filters)\n",
    "        # filters = np.repeat(filters, inc, axis=1)\n",
    "        filters = np.repeat(filters, inc, axis=0)\n",
    "        filters = torch.FloatTensor(filters)    # (3,3,5,5)\n",
    "        # print(filters.size())\n",
    "        return filters\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = torch.rand(1, 3, 224, 224)\n",
    "    srm = SRMConv2d_simple()\n",
    "    output = srm(x)\n",
    "    output = np.array(output)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp(\n",
      "  (srm): SRMConv2d_simple(\n",
      "    (truc): Hardtanh(min_val=-3, max_val=3)\n",
      "  )\n",
      "  (disc): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#ssp.py\n",
    "class ssp(nn.Module):\n",
    "    def __init__(self, pretrain=True):\n",
    "        super().__init__()\n",
    "        self.srm = SRMConv2d_simple()\n",
    "        self.disc = resnet50(pretrained=True)\n",
    "        self.disc.fc = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, (256, 256), mode='bilinear')\n",
    "        x = self.srm(x)\n",
    "        x = self.disc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = ssp(pretrain=True)\n",
    "    print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.py\n",
    "import random\n",
    "def compute(patch):\n",
    "    weight, height = patch.size\n",
    "    m = weight\n",
    "    res = 0\n",
    "    patch = np.array(patch).astype(np.int64)\n",
    "    diff_horizontal = np.sum(np.abs(patch[:, :-1, :] - patch[:, 1:, :]))\n",
    "    diff_vertical = np.sum(np.abs(patch[:-1, :, :] - patch[1:, :, :]))\n",
    "    diff_diagonal = np.sum(np.abs(patch[:-1, :-1, :] - patch[1:, 1:, :]))\n",
    "    diff_diagonal += np.sum(np.abs(patch[1:, :-1, :] - patch[:-1, 1:, :]))\n",
    "    res = diff_horizontal + diff_vertical + diff_diagonal\n",
    "    return res.sum()\n",
    "\n",
    "\n",
    "def patch_img(img, patch_size, height):\n",
    "    img_width, img_height = img.size\n",
    "    num_patch = (height // patch_size) * (height // patch_size)\n",
    "    patch_list = []\n",
    "    min_len = min(img_height, img_width)\n",
    "    rz = transforms.Resize((height, height))\n",
    "    if min_len < patch_size:\n",
    "        img = rz(img)\n",
    "    rp = transforms.RandomCrop(patch_size)\n",
    "    for i in range(num_patch):\n",
    "        patch_list.append(rp(img))\n",
    "    patch_list.sort(key=lambda x: compute(x), reverse=False)\n",
    "    new_img = patch_list[0]\n",
    "    return new_img\n",
    "\n",
    "def set_random_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader.py\n",
    "class Opt:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "class genImageValDataset(Dataset):\n",
    "    def __init__(self, image_root, image_dir, is_real, opt):\n",
    "        super().__init__()\n",
    "        self.opt = opt\n",
    "        self.root = os.path.join(image_root, image_dir, \"val\")\n",
    "        if is_real:\n",
    "            self.img_path = os.path.join(self.root, '0_real')\n",
    "            self.img_list = [os.path.join(self.img_path, f) for f in os.listdir(self.img_path)]\n",
    "            self.img_len = len(self.img_list)\n",
    "            self.labels = torch.zeros(self.img_len)\n",
    "        else:\n",
    "            self.img_path = os.path.join(self.root, '1_fake')\n",
    "            self.img_list = [os.path.join(self.img_path, f) for f in os.listdir(self.img_path)]\n",
    "            self.img_len = len(self.img_list)\n",
    "            self.labels = torch.ones(self.img_len)\n",
    "\n",
    "    def rgb_loader(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.rgb_loader(self.img_list[index])\n",
    "        label = self.labels[index]\n",
    "        image = processing(image, self.opt)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.img_len\n",
    "\n",
    "def sample_continuous(s):\n",
    "    if len(s) == 1:\n",
    "        return s[0]\n",
    "    if len(s) == 2:\n",
    "        rg = s[1] - s[0]\n",
    "        return random.random() * rg + s[0]\n",
    "    raise ValueError(\"Length of iterable s should be 1 or 2.\")\n",
    "\n",
    "\n",
    "def sample_discrete(s):\n",
    "    if len(s) == 1:\n",
    "        return s[0]\n",
    "    return random.choice(s)\n",
    "\n",
    "\n",
    "def sample_randint(s):\n",
    "    if len(s) == 1:\n",
    "        return s[0]\n",
    "    return rd.randint(s[0], s[1])\n",
    "\n",
    "\n",
    "def gaussian_blur_gray(img, sigma):\n",
    "    if len(img.shape) == 3:\n",
    "        img_blur = np.zeros_like(img)\n",
    "        for i in range(img.shape[2]):\n",
    "            img_blur[:, :, i] = gaussian_filter(img[:, :, i], sigma=sigma)\n",
    "    else:\n",
    "        img_blur = gaussian_filter(img, sigma=sigma)\n",
    "    return img_blur\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:, :, 0], output=img[:, :, 0], sigma=sigma)\n",
    "    gaussian_filter(img[:, :, 1], output=img[:, :, 1], sigma=sigma)\n",
    "    gaussian_filter(img[:, :, 2], output=img[:, :, 2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:, :, ::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:, :, ::-1]\n",
    "\n",
    "\n",
    "def pil_jpg(img, compress_val):\n",
    "    out = BytesIO()\n",
    "    img = Image.fromarray(img)\n",
    "    img.save(out, format='jpeg', quality=compress_val)\n",
    "    img = Image.open(out)\n",
    "    # load from memory before ByteIO closes\n",
    "    img = np.array(img)\n",
    "    out.close()\n",
    "    return img\n",
    "\n",
    "\n",
    "jpeg_dict = {'cv2': cv2_jpg, 'pil': pil_jpg}\n",
    "\n",
    "\n",
    "def jpeg_from_key(img, compress_val, key):\n",
    "    method = jpeg_dict[key]\n",
    "    return method(img, compress_val)\n",
    "\n",
    "\n",
    "def data_augment(img, opt):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < opt.blur_prob:\n",
    "        sig = sample_continuous(opt.blur_sig)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < opt.jpg_prob:\n",
    "        method = sample_discrete(opt.jpg_method)\n",
    "        qual = sample_randint(opt.jpg_qual)\n",
    "        img = jpeg_from_key(img, qual, method)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def processing(img, opt):\n",
    "    if opt.aug:\n",
    "        aug = transforms.Lambda(\n",
    "            lambda img: data_augment(img, opt)\n",
    "        )\n",
    "    else:\n",
    "        aug = transforms.Lambda(\n",
    "            lambda img: img\n",
    "        )\n",
    "\n",
    "    if opt.isPatch:\n",
    "        patch_func = transforms.Lambda(\n",
    "            lambda img: patch_img(img, opt.patch_size, opt.trainsize))\n",
    "    else:\n",
    "        patch_func = transforms.Resize((256, 256))\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        aug,\n",
    "        patch_func,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    return trans(img)\n",
    "\n",
    "\n",
    "def get_single_loader(opt, image_dir, is_real): \n",
    "    val_dataset = genImageValDataset(opt.image_root, image_dir=image_dir, is_real=is_real, opt=opt)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=opt.val_batchsize, shuffle=False, pin_memory=True)\n",
    "    return val_loader, len(val_dataset)\n",
    "\n",
    "\n",
    "def get_test_data_list(opt):\n",
    "    choices = opt.choices\n",
    "    test_dir = opt.test_set_dir\n",
    "    dicts_per_has_loader_info = []\n",
    "    dict_loader_info=dict()\n",
    "    if choices[0] == 2:\n",
    "        print(\"val on:\", test_dir)\n",
    "        dict_loader_info['name'] = test_dir\n",
    "        dict_loader_info['val_ai_loader'], dict_loader_info['ai_size'] = get_single_loader(opt, dict_loader_info['name'], is_real=False)\n",
    "        dict_loader_info['val_nature_loader'], dict_loader_info['nature_size'] = get_single_loader(opt, dict_loader_info['name'], is_real=True)\n",
    "        dicts_per_has_loader_info.append(dict_loader_info)\n",
    "    return dicts_per_has_loader_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Author: suqiulin\n",
    "@Email: 72405483@cityu-dg.edu.cn\n",
    "@Date: 2024/12/3\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Currently assumes jpg_prob, blur_prob 0 or 1\"\"\"\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def print_per_pic_res(batch_index, size, current_prediction, label_name, val_label_loader):\n",
    "    print(f\"checking on {batch_index}th batch {label_name} datas:\")\n",
    "    data = []\n",
    "    for i in range(len(current_prediction)):\n",
    "        img_path = val_label_loader.dataset.img_list[batch_index * size + i]\n",
    "        last_path = os.path.basename(img_path)\n",
    "        is_label = current_prediction[i]\n",
    "        data.append([last_path, is_label])\n",
    "    df = pd.DataFrame(data, columns=[\"img_name\", f\"is_{label_name}\"])\n",
    "    display(df)\n",
    "\n",
    "def traversal_label_loader(label_loader, label_size, print_gap=None):  \n",
    "    #/xxxxx/imagenet_cityu_test/val/ai/yy.jpg\n",
    "    demo_path = label_loader.dataset.img_list[0]\n",
    "    #保留'ai'\n",
    "    label_name = os.path.basename(os.path.dirname(demo_path))\n",
    "    right_label_image = 0\n",
    "    for batch_index, (images, labels) in enumerate(label_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda() \n",
    "            labels = labels.cuda()\n",
    "        res = model(images)\n",
    "        res = torch.sigmoid(res).ravel()\n",
    "        current_prediction = (((res > 0.5) & (labels == 0)) | ((res < 0.5) & (labels == 1))).cpu().numpy()\n",
    "        # 一个batch是64,数据大的情况下，每隔print_gap*64个图片才打印一次识别\n",
    "        if (print_gap is not None) and batch_index % print_gap == 0 :\n",
    "            print_per_pic_res(batch_index, len(images), current_prediction, label_name, label_loader)\n",
    "        right_label_image += current_prediction.sum()\n",
    "    print(f'{label_name} accu:{right_label_image / label_size}')\n",
    "    return right_label_image\n",
    "\n",
    "def val(val_loader, model, print_gap=None):\n",
    "    model.eval()\n",
    "    total_right_image = total_image = 0\n",
    "    with torch.no_grad():\n",
    "        for loader in val_loader:\n",
    "            name, val_ai_loader, ai_size, val_nature_loader, nature_size = loader['name'], loader['val_ai_loader'], loader['ai_size'], loader['val_nature_loader'], loader['nature_size']\n",
    "            print(\"val on:\", name)\n",
    "            right_ai_image = traversal_label_loader(val_ai_loader, ai_size, print_gap)\n",
    "            right_nature_image = traversal_label_loader(val_nature_loader, nature_size, print_gap)\n",
    "            accu = (right_ai_image + right_nature_image) / (ai_size + nature_size)\n",
    "            total_right_image += right_ai_image + right_nature_image\n",
    "            total_image += ai_size + nature_size\n",
    "            print(f'val on:{name}, Accuracy:{accu}')\n",
    "    total_accu = total_right_image / total_image\n",
    "    print(f'total accuracy:{total_accu}')\n",
    "\n",
    "def get_options():\n",
    "    options = {\n",
    "        'name': 'experiment_name',\n",
    "        'rz_interp': 'bilinear',\n",
    "        'blur_prob': 0,\n",
    "        'blur_sig': [0, 1],\n",
    "        'jpg_prob': 0,\n",
    "        'jpg_method': ['pil', 'cv2'],\n",
    "        'jpg_qual': [90, 100],\n",
    "        'CropSize': 224,\n",
    "        'batchsize': 64,\n",
    "        'choices': [1],\n",
    "        'epoch': 30,\n",
    "        'lr': 1e-4,\n",
    "        'trainsize': 256,\n",
    "        'load': './snapshot/sortnet/cityu.pth',\n",
    "        'image_root': '/root/autodl-fs/genImage',\n",
    "        'save_path': './snapshot/sortnet/',\n",
    "        'isPatch': True,\n",
    "        'patch_size': 32,\n",
    "        'aug': True,\n",
    "        'gpu_id': '0',\n",
    "        'log_name': 'log3.log',\n",
    "        'val_interval': 1,\n",
    "        'val_batchsize': 64,\n",
    "        'test_set_dir': None,\n",
    "        'print_gap':2\n",
    "    }\n",
    "    opt = Opt(**options)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Only need to modify is just the below cell, other cells should remain still.\n",
    "# 2. The code will choose GPU or CPU automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not specify the absolute path of test dataset\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "def rewrite_test_opt(test_dataset_path):\n",
    "    test_opt = get_options()\n",
    "    test_opt.choices = [2]\n",
    "    test_opt.image_root = os.path.dirname(test_dataset_path)\n",
    "    test_opt.test_set_dir = test_dataset_path\n",
    "    #务必保证snapshot在同级目录下，如果加载不成功要修改为绝对路径\n",
    "    #------------------------------------------------------------!!!2.可能需要修改的点2-已训练模型的路径(大概率不用)\n",
    "    test_opt.load =  './cityu.pth'\n",
    "    #每隔64*print_gap个图片打印改批次识别情况\n",
    "    test_opt.print_gap = 20\n",
    "    return test_opt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    set_random_seed()\n",
    "    #------------------------------------------------------------!!!1.可能需要修改的点-测试数据集所在的文件夹【绝对路径】\n",
    "    #All you need to do is just to modify this variate\n",
    "    test_dataset_absolute_path = ''\n",
    "\n",
    "    if  not test_dataset_absolute_path:\n",
    "        print(\"Not specify the absolute path of test dataset\")\n",
    "        sys.exit(1)\n",
    "    test_opt = rewrite_test_opt(test_dataset_absolute_path)\n",
    "    \n",
    "    if torch.cuda.is_available() and test_opt.gpu_id == '0':\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "        print('USE GPU 0')\n",
    "\n",
    "    # load data\n",
    "    print('load data...')\n",
    "    val_loader = get_test_data_list(test_opt)\n",
    "\n",
    "    enable_cuda = torch.cuda.is_available()\n",
    "    model = ssp().cuda() if enable_cuda else ssp()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "   \n",
    "    if test_opt.load is None:\n",
    "        print(\"not found model\")\n",
    "    model.load_state_dict(torch.load(test_opt.load, map_location=device))\n",
    "    print('load model from', test_opt.load)\n",
    "    print(\"Start test\")\n",
    "        \n",
    "    val(val_loader, model, test_opt.print_gap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
